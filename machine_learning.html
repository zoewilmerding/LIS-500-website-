<!DOCTYPE html>
<html>
	<head> 
		<title>Machine Learning</title>
		<link rel="stylesheet" text="text/css" href="stylesheet2.css">
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@500;700&display=swap" rel="stylesheet">

</head>

	<body>
		<header> 
		<h1>Machine Learning </h1>
		<nav> 
			<ul>
				<li><a href="index.html">Home</a></li> 
				<li><a href="about.html">About us</a></li> 
				<li><a href="resources.html">Resources</a></li>
				<li><a href="tech_hero.html">Tech Hero</a></li>
       		 	<li><a href="machine_learning.html">Machine Learning</a></li>
			</ul>
		</nav>
</header>
<section>
	<main>
		<article class="mart">
			<h2 id = "title"> Project Objectives  </h2>
			
			<p>  TEXT </p>
			
			<h2 id = "title"> Project Scope </h2>
			
			<p> 
			Classification: Determining Different Emotions <br>
			Range: 3 Emotions <br>
			Emotion's Listed: Happy , Neutral , Sad <br>
			Image Samples: 60-80 images for each classified item <br>
			<img src="PNG image.jpeg" alt="IMG" width="500" height="400" />		
			
			</p>
			
			<h2 id = "title"> Reflections On Our Project & Unmasking AI by Joy Bolumawani </h2>
			
			<p>  Our machine learning technology teaches the computer how to recognize three basic facial expressions, accompanied by three basic hand motions: Happy, Neutral, and Sad, represented by thumbs up, middle, and down. By using dozens of pictures of Amanda recreating these facial features, we trained the teachable machine model to distinguish between these faces. The lessons from Joy Buolamwini's Unmasking AI translate to practical and ethical decisions we had to make in the process. Despite our project being a scaled-back version of machine learning, the arguments Boulamwini makes on data, power, and representation were very evident throughout the process. ​
We began by deciding which expressions to include. We chose happy, neutral, and sad because they are among the most commonly recognized emotional states and could be reliably demonstrated by any user. Once we finalized our categories, Amanda collected the photo data for each class using the Teachable Machine interface. We quickly ran into the issue that this machine was having trouble accurately attributing the right facial expression to the correct emotion. So we decided to also hold a thumbs up with happiness,  a thumb in the middle with neutral, and a thumbs down with sadness. Adding a hand signal easily allowed the machine to identify the correct emotion. When creating this machine learning technology, we found ourselves running into many of the same issues Buolamwini raises around bias when building technology. 
One concept from the book that we discussed through the creation of our machine learning tool was the idea of “Coded Gaze.” This term explains how people who design and train these AI systems will subconsciously and unintentionally pass personal preferences or experiences onto the technology. As we consciously took repetitive photos, we realized that we were the ones who decided what counted as happy, neutral, or sad. We were training this model to interpret our emotions through our lenses. Thus, proving to us Boulamwini's point that these machines become biased based on what they learn from limited human perspectives. 
As Boulamwini discussed in her book, AI systems are never neutral, as every classification reflects a human decision. When building our model, we first wanted the machine to identify emotions just based on our faces. However, when we tested, we found that neutral expressions were extremely hard for the model to recognize.  This is because a neutral expression is very subjective. What each of our group members considered neutral emotion was not consistent. This showed us firsthand what Buolamwini expresses when she says that these systems are classified and shaped by human perspectives. 
As we continued to test our model, we saw that the system confidently misclassified subtle expression differences. Highlighting the gap between intent and impact. Showing that many harmful AI outcomes occur because the system misreads or misinterprets the images. While these mistakes were harmless for us, they showed how easy it is for AI to make simple mistakes that could negatively affect users.
Building this small version of a machine learning tool prompted us to think critically about the ethical principles that support AI development. This tool showed us the importance of ethical reflection in every stage of AI development. This project directly translated the themes from Unmasking AI into our own practice. This project opened our eyes to the small details that go into machine learning and the impact small design choices have on the design.
</p>
			
			<h2 id = "title"> Model Video Example  </h2>
			
			<p> 
				<video width="640" height="360" controls>
    <source src="Teachable Machine.mp4" type="video/mp4">
    </video>
				
   			</p>
			<h2 id = "title"> Test our Model! </h2>
			
			<p>  <a href="https://teachablemachine.withgoogle.com/models/GWs1-9pCX/"> Our Model </a> </p>
		</article>
</section>

	</body>

</html>
